# ì œì¡° ê³µì • ìë™í™” êµ¬í˜„ ê³„íš
## ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ìë™ ì¬ê³  ì´ë™ ì‹œìŠ¤í…œ

**í”„ë¡œì íŠ¸**: íƒœì°½ ERP í˜„ì¥ í”„ë¡œì„¸ìŠ¤ ìë™í™”
**ëª©í‘œ**: ì¡°ì„±ì§„ ì°¨ì¥ë‹˜ ìš”êµ¬ì‚¬í•­ 100% ì¶©ì¡±
**ê¸°ê°„**: 9-10ì¼ (Wave ê¸°ë°˜ ë³‘ë ¬ ì‹¤í–‰)
**ìš°ì„ ìˆœìœ„**: CRITICAL - ì™„ë²½í•œ êµ¬í˜„ í•„ìˆ˜

---

## ğŸ¯ í•µì‹¬ ìš”êµ¬ì‚¬í•­ (ì¡°ì„±ì§„ ì°¨ì¥ë‹˜)

### 1. ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ìë™ ì¬ê³  ì´ë™
**í˜„ì¬ ë¬¸ì œ**: ê³µì • ì™„ë£Œ ì‹œ ì¬ê³ ê°€ ìˆ˜ë™ìœ¼ë¡œë§Œ ì´ë™ë¨
**í•´ê²°ì±…**: `auto_process_stock_movement()` íŠ¸ë¦¬ê±°ë¡œ ì™„ì „ ìë™í™”

### 2. BOMê³¼ ì‹¤ì œ ê³µì • ë°ì´í„° íë¦„ ì¼ì¹˜
**í˜„ì¬ ë¬¸ì œ**: BOMì€ ìˆì§€ë§Œ ê³µì • íë¦„ê³¼ ë¶„ë¦¬ë¨
**í•´ê²°ì±…**:
- process_chain_definitions í…Œì´ë¸”ë¡œ ê³µì • ì²´ì¸ ì •ì˜
- auto_next_operationìœ¼ë¡œ ìë™ ë‹¤ìŒ ê³µì • ì‹œì‘
- LOT genealogyë¡œ ì½”ì¼â†’íŒì¬â†’ì™„ì œí’ˆ ì¶”ì 

---

## ğŸ“Š Wave ì‹¤í–‰ ì „ëµ (9-10ì¼)

### Wave 1: Foundation Design (Day 1-2) - 3 Parallel Tracks
**Track A**: Database Schema Design
- Agent: database-architect
- Tasks: 6ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ê³„
- Output: SQL migration files

**Track B**: API Architecture Planning
- Agent: backend-architect
- Tasks: 5ê°œ API ì—”ë“œí¬ì¸íŠ¸ ì„¤ê³„
- Output: API specification

**Track C**: UI Component Design
- Agent: frontend-developer
- Tasks: ì»´í¬ë„ŒíŠ¸ ì™€ì´ì–´í”„ë ˆì„
- Output: Component specifications

### Wave 2: Core Implementation (Day 3-5) - 4 Parallel Tracks
**Track A**: Database Migrations
- Agent: database-architect + supabase-schema-architect
- Tasks: 6ê°œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©
- Critical: Migration 3 (auto_process_stock_movement trigger)

**Track B**: Backend APIs
- Agent: backend-architect
- Tasks: 5ê°œ API êµ¬í˜„
- Critical: POST /api/process/complete (íŠ¸ë¦¬ê±° í™œì„±í™”)

**Track C**: Frontend Components
- Agent: frontend-developer
- Tasks: 3+ React ì»´í¬ë„ŒíŠ¸
- Features: Batch mode, Chain mode UI

**Track D**: RLS Policies
- Agent: supabase-schema-architect
- Tasks: ë³´ì•ˆ ì •ì±… êµ¬í˜„

### Wave 3: Advanced Features (Day 6-7) - 3 Parallel Tracks
**Track A**: Batch Processing
- Agent: backend-architect + frontend-developer
- Feature: ë‹¤ì¤‘ ê³µì • ë™ì‹œ ì‹¤í–‰

**Track B**: Chain Automation
- Agent: backend-architect
- Feature: ì½”ì¼â†’íŒì¬â†’ë‚©í’ˆ ìë™ ì²´ì¸

**Track C**: Real-time Dashboard
- Agent: frontend-developer
- Feature: ê³µì • í˜„í™© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

### Wave 4: Testing & Optimization (Day 8-9) - 2 Parallel Tracks
**Track A**: E2E Testing
- Agent: qa persona
- Critical Test: ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ì „ì²´ íë¦„
- Validation: ì¬ê³  ìë™ ì´ë™, LOT ì¶”ì 

**Track B**: Performance Optimization
- Agent: performance persona
- Tasks: ì¿¼ë¦¬ ìµœì í™”, ì¸ë±ìŠ¤ íŠœë‹

### Wave 5: Production Deployment (Day 10) - 1 Track
**Track A**: Deployment & Monitoring
- Agent: devops persona
- Tasks: ë§ˆì´ê·¸ë ˆì´ì…˜ ë°°í¬, ëª¨ë‹ˆí„°ë§ ì„¤ì •

---

## ğŸ—„ï¸ Database Migrations (6ê°œ)

### Migration 1: create_stock_history.sql
**ëª©ì **: ëª¨ë“  ì¬ê³  ì´ë™ì˜ ì™„ì „í•œ ê°ì‚¬ ì¶”ì 
**ìœ„í—˜ë„**: LOW (ì‹ ê·œ í…Œì´ë¸”)

```sql
-- Migration: create_stock_history.sql
-- Purpose: Complete audit trail for all inventory movements
-- Risk: LOW - New table, no existing data affected

CREATE TABLE IF NOT EXISTS stock_history (
  history_id BIGSERIAL PRIMARY KEY,
  item_id INTEGER NOT NULL REFERENCES items(item_id) ON DELETE CASCADE,

  -- Change tracking
  change_type VARCHAR(50) NOT NULL CHECK (change_type IN (
    'PURCHASE', 'SALES', 'PRODUCTION', 'ADJUSTMENT', 'TRANSFER', 'RETURN',
    'PROCESS_INPUT', 'PROCESS_OUTPUT', 'BLANKING', 'PRESS', 'ASSEMBLY',
    'LOT_TRANSFER', 'SHIPPING', 'SCRAP', 'QUALITY_FAIL'
  )),

  quantity_change DECIMAL(15, 2) NOT NULL,
  stock_before DECIMAL(15, 2) NOT NULL,
  stock_after DECIMAL(15, 2) NOT NULL,

  -- Reference tracking
  reference_type VARCHAR(50), -- 'process_operation', 'inventory_transaction', etc.
  reference_id INTEGER,

  -- LOT tracking
  lot_number VARCHAR(100),
  batch_number VARCHAR(100),

  -- Metadata
  notes TEXT,
  created_by INTEGER,
  created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

-- Indexes for performance
CREATE INDEX idx_stock_history_item_date ON stock_history(item_id, created_at DESC);
CREATE INDEX idx_stock_history_reference ON stock_history(reference_type, reference_id);
CREATE INDEX idx_stock_history_lot ON stock_history(lot_number) WHERE lot_number IS NOT NULL;
CREATE INDEX idx_stock_history_recent ON stock_history(created_at DESC) WHERE created_at > NOW() - INTERVAL '30 days';

-- Enable RLS
ALTER TABLE stock_history ENABLE ROW LEVEL SECURITY;

-- RLS Policy: Allow all authenticated users to read
CREATE POLICY "Allow authenticated read on stock_history"
  ON stock_history FOR SELECT
  USING (true);

-- RLS Policy: Only system can insert (via triggers)
CREATE POLICY "System only insert on stock_history"
  ON stock_history FOR INSERT
  WITH CHECK (created_by IS NOT NULL);

COMMENT ON TABLE stock_history IS 'ì¬ê³  ë³€ë™ ì´ë ¥ ì¶”ì  - ëª¨ë“  ì¬ê³  ì´ë™ì˜ ì™„ì „í•œ ê°ì‚¬ ì¶”ì ';
COMMENT ON COLUMN stock_history.change_type IS 'ë³€ë™ ìœ í˜• - BLANKING(ì½”ì¼â†’íŒì¬), PRESS(íŒì¬â†’ì„±í˜•í’ˆ) ë“±';
COMMENT ON COLUMN stock_history.lot_number IS 'LOT ë²ˆí˜¸ - BLK-YYYYMMDD-XXX í˜•ì‹';
```

### Migration 2: extend_process_operations.sql
**ëª©ì **: process_operations í…Œì´ë¸” í™•ì¥ (ê³µì • ì²´ì¸, LOT ì¶”ì )
**ìœ„í—˜ë„**: MEDIUM (ê¸°ì¡´ í…Œì´ë¸” ë³€ê²½)

```sql
-- Migration: extend_process_operations.sql
-- Purpose: Extend process_operations for chain management and LOT tracking
-- Risk: MEDIUM - Altering existing table

-- Add new columns for process chain management
ALTER TABLE process_operations
  ADD COLUMN IF NOT EXISTS parent_operation_id INTEGER REFERENCES process_operations(operation_id),
  ADD COLUMN IF NOT EXISTS chain_id VARCHAR(100),
  ADD COLUMN IF NOT EXISTS chain_sequence INTEGER,

  -- LOT tracking
  ADD COLUMN IF NOT EXISTS lot_number VARCHAR(100) UNIQUE,
  ADD COLUMN IF NOT EXISTS parent_lot_number VARCHAR(100),
  ADD COLUMN IF NOT EXISTS child_lot_number VARCHAR(100),

  -- Batch tracking
  ADD COLUMN IF NOT EXISTS batch_id VARCHAR(100),

  -- Auto-processing flags
  ADD COLUMN IF NOT EXISTS auto_next_operation BOOLEAN DEFAULT FALSE,
  ADD COLUMN IF NOT EXISTS next_operation_type VARCHAR(50),

  -- Additional metrics
  ADD COLUMN IF NOT EXISTS scrap_quantity DECIMAL(15, 2) DEFAULT 0,
  ADD COLUMN IF NOT EXISTS quality_status VARCHAR(20) DEFAULT 'PASS' CHECK (quality_status IN ('PASS', 'FAIL', 'PENDING'));

-- Indexes
CREATE INDEX idx_process_operations_chain ON process_operations(chain_id, chain_sequence) WHERE chain_id IS NOT NULL;
CREATE INDEX idx_process_operations_lot ON process_operations(lot_number) WHERE lot_number IS NOT NULL;
CREATE INDEX idx_process_operations_parent_lot ON process_operations(parent_lot_number) WHERE parent_lot_number IS NOT NULL;
CREATE INDEX idx_process_operations_batch ON process_operations(batch_id) WHERE batch_id IS NOT NULL;

-- Function: Generate LOT number
-- Format: {OPERATION_TYPE_PREFIX}-YYYYMMDD-XXX
-- Example: BLK-20250205-001, PRS-20250205-001
CREATE OR REPLACE FUNCTION generate_lot_number(
  p_operation_type VARCHAR,
  p_item_id INTEGER
)
RETURNS VARCHAR AS $$
DECLARE
  v_prefix VARCHAR(3);
  v_date_str VARCHAR(8);
  v_sequence INTEGER;
  v_lot_number VARCHAR(100);
BEGIN
  -- Determine prefix based on operation type
  v_prefix := CASE p_operation_type
    WHEN 'BLANKING' THEN 'BLK'
    WHEN 'PRESS' THEN 'PRS'
    WHEN 'ASSEMBLY' THEN 'ASM'
    WHEN 'WELDING' THEN 'WLD'
    WHEN 'PAINTING' THEN 'PNT'
    WHEN 'SHIPPING' THEN 'SHP'
    ELSE 'OTH'
  END;

  -- Get current date string (YYYYMMDD)
  v_date_str := TO_CHAR(NOW(), 'YYYYMMDD');

  -- Get next sequence number for today
  SELECT COALESCE(MAX(
    CAST(SUBSTRING(lot_number FROM LENGTH(v_prefix || '-' || v_date_str || '-') + 1) AS INTEGER)
  ), 0) + 1
  INTO v_sequence
  FROM process_operations
  WHERE lot_number LIKE v_prefix || '-' || v_date_str || '-%';

  -- Format: BLK-20250205-001
  v_lot_number := v_prefix || '-' || v_date_str || '-' || LPAD(v_sequence::TEXT, 3, '0');

  RETURN v_lot_number;
END;
$$ LANGUAGE plpgsql;

COMMENT ON FUNCTION generate_lot_number IS 'LOT ë²ˆí˜¸ ìë™ ìƒì„± - BLK-YYYYMMDD-XXX í˜•ì‹';
COMMENT ON COLUMN process_operations.chain_id IS 'ê³µì • ì²´ì¸ ID - ì—°ê²°ëœ ê³µì •ë“¤ì˜ ê·¸ë£¹ ì‹ë³„ì';
COMMENT ON COLUMN process_operations.lot_number IS 'í˜„ì¬ LOT ë²ˆí˜¸';
COMMENT ON COLUMN process_operations.parent_lot_number IS 'ë¶€ëª¨ LOT ë²ˆí˜¸ (ì´ì „ ê³µì •ì˜ LOT)';
COMMENT ON COLUMN process_operations.child_lot_number IS 'ìì‹ LOT ë²ˆí˜¸ (ë‹¤ìŒ ê³µì •ì˜ LOT)';
```

### Migration 3: create_auto_stock_movement_trigger.sql (ğŸ”¥ CRITICAL)
**ëª©ì **: ê³µì • ì™„ë£Œ ì‹œ ì¬ê³  ìë™ ì´ë™ (ì½”ì¼ â†’ íŒì¬ í•µì‹¬ ê¸°ëŠ¥!)
**ìœ„í—˜ë„**: HIGH (í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)

```sql
-- Migration: create_auto_stock_movement_trigger.sql
-- Purpose: Automatic stock movement when process completes
-- Risk: HIGH - Critical business logic automation
-- THIS IS THE CORE OF ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ AUTOMATION!

CREATE OR REPLACE FUNCTION auto_process_stock_movement()
RETURNS TRIGGER AS $$
DECLARE
  v_available_stock DECIMAL(15, 2);
  v_stock_before_input DECIMAL(15, 2);
  v_stock_before_output DECIMAL(15, 2);
  v_stock_after_input DECIMAL(15, 2);
  v_stock_after_output DECIMAL(15, 2);
  v_next_operation_id INTEGER;
  v_child_lot VARCHAR(100);
  v_input_item_name VARCHAR(200);
  v_output_item_name VARCHAR(200);
BEGIN
  -- Only process when status changes to COMPLETED
  IF NEW.status = 'COMPLETED' AND (OLD.status IS NULL OR OLD.status != 'COMPLETED') THEN

    RAISE NOTICE '=== ê³µì • ì™„ë£Œ ì¬ê³  ì´ë™ ì‹œì‘ ===';
    RAISE NOTICE 'Operation ID: %, Type: %', NEW.operation_id, NEW.operation_type;
    RAISE NOTICE 'Input Item: % (Qty: %)', NEW.input_item_id, NEW.input_quantity;
    RAISE NOTICE 'Output Item: % (Qty: %)', NEW.output_item_id, NEW.output_quantity;

    -- Get item names for logging
    SELECT item_name INTO v_input_item_name FROM items WHERE item_id = NEW.input_item_id;
    SELECT item_name INTO v_output_item_name FROM items WHERE item_id = NEW.output_item_id;

    -- 1. VALIDATE STOCK AVAILABILITY
    SELECT current_stock INTO v_available_stock
    FROM items
    WHERE item_id = NEW.input_item_id;

    IF v_available_stock < NEW.input_quantity THEN
      RAISE EXCEPTION 'ì¬ê³  ë¶€ì¡±: % (í•„ìš”: %, í˜„ì¬: %)',
        v_input_item_name, NEW.input_quantity, v_available_stock;
    END IF;

    RAISE NOTICE 'ì¬ê³  ê²€ì¦ ì™„ë£Œ: % í˜„ì¬ê³  %', v_input_item_name, v_available_stock;

    -- 2. CAPTURE STOCK LEVELS BEFORE CHANGE
    SELECT current_stock INTO v_stock_before_input
    FROM items WHERE item_id = NEW.input_item_id;

    SELECT current_stock INTO v_stock_before_output
    FROM items WHERE item_id = NEW.output_item_id;

    RAISE NOTICE 'ì´ë™ ì „ ì¬ê³ : Input(%) %, Output(%) %',
      v_input_item_name, v_stock_before_input,
      v_output_item_name, v_stock_before_output;

    -- 3. UPDATE STOCKS (ì½”ì¼ â†’ íŒì¬ ìë™ ì¬ê³  ì´ë™!)
    -- Deduct input item stock
    UPDATE items
    SET current_stock = current_stock - NEW.input_quantity,
        updated_at = NOW()
    WHERE item_id = NEW.input_item_id;

    -- Add output item stock
    UPDATE items
    SET current_stock = current_stock + NEW.output_quantity,
        updated_at = NOW()
    WHERE item_id = NEW.output_item_id;

    RAISE NOTICE 'ì¬ê³  ì´ë™ ì™„ë£Œ!';

    -- 4. CAPTURE STOCK LEVELS AFTER CHANGE
    SELECT current_stock INTO v_stock_after_input
    FROM items WHERE item_id = NEW.input_item_id;

    SELECT current_stock INTO v_stock_after_output
    FROM items WHERE item_id = NEW.output_item_id;

    RAISE NOTICE 'ì´ë™ í›„ ì¬ê³ : Input(%) %, Output(%) %',
      v_input_item_name, v_stock_after_input,
      v_output_item_name, v_stock_after_output;

    -- 5. RECORD INPUT STOCK HISTORY (ê°ì†Œ)
    INSERT INTO stock_history (
      item_id, change_type, quantity_change,
      stock_before, stock_after,
      reference_type, reference_id,
      lot_number, notes, created_at
    )
    VALUES (
      NEW.input_item_id,
      NEW.operation_type || '_INPUT',
      -NEW.input_quantity,
      v_stock_before_input,
      v_stock_after_input,
      'process_operation',
      NEW.operation_id,
      NEW.lot_number,
      FORMAT('ê³µì • ì™„ë£Œ íˆ¬ì…: %s â†’ %s (LOT: %s)',
        v_input_item_name, NEW.operation_type, NEW.lot_number),
      NOW()
    );

    -- 6. RECORD OUTPUT STOCK HISTORY (ì¦ê°€)
    INSERT INTO stock_history (
      item_id, change_type, quantity_change,
      stock_before, stock_after,
      reference_type, reference_id,
      lot_number, notes, created_at
    )
    VALUES (
      NEW.output_item_id,
      NEW.operation_type || '_OUTPUT',
      NEW.output_quantity,
      v_stock_before_output,
      v_stock_after_output,
      'process_operation',
      NEW.operation_id,
      NEW.lot_number,
      FORMAT('ê³µì • ì™„ë£Œ ì‚°ì¶œ: %s ìƒì‚° (LOT: %s)',
        NEW.operation_type, NEW.lot_number),
      NOW()
    );

    RAISE NOTICE 'ì¬ê³  ì´ë ¥ ê¸°ë¡ ì™„ë£Œ';

    -- 7. AUTO-START NEXT OPERATION (ì²´ì¸ ìë™í™”)
    IF NEW.auto_next_operation = TRUE AND NEW.next_operation_type IS NOT NULL THEN
      RAISE NOTICE 'ë‹¤ìŒ ê³µì • ìë™ ì‹œì‘: %', NEW.next_operation_type;

      -- Generate child LOT number
      v_child_lot := generate_lot_number(NEW.next_operation_type, NEW.output_item_id);

      RAISE NOTICE 'ìì‹ LOT ìƒì„±: %', v_child_lot;

      -- Create next operation
      INSERT INTO process_operations (
        operation_type,
        input_item_id,
        input_quantity,
        output_item_id,
        output_quantity,
        parent_operation_id,
        chain_id,
        chain_sequence,
        lot_number,
        parent_lot_number,
        status,
        scheduled_date,
        created_at
      )
      SELECT
        NEW.next_operation_type,
        NEW.output_item_id, -- ì´ì „ ê³µì •ì˜ outputì´ ë‹¤ìŒ ê³µì •ì˜ input!
        NEW.output_quantity,
        NEW.output_item_id, -- Placeholder, actual output ê²°ì •ì€ ë‚˜ì¤‘ì—
        NEW.output_quantity, -- Expected output
        NEW.operation_id,
        NEW.chain_id,
        COALESCE(NEW.chain_sequence, 0) + 1,
        v_child_lot,
        NEW.lot_number,
        'PENDING',
        NOW(),
        NOW()
      RETURNING operation_id INTO v_next_operation_id;

      -- Update current operation's child LOT
      UPDATE process_operations
      SET child_lot_number = v_child_lot
      WHERE operation_id = NEW.operation_id;

      RAISE NOTICE 'ë‹¤ìŒ ê³µì • ìƒì„± ì™„ë£Œ: Operation ID %', v_next_operation_id;
    END IF;

    RAISE NOTICE '=== ê³µì • ì™„ë£Œ ì¬ê³  ì´ë™ ì¢…ë£Œ ===';
  END IF;

  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create trigger
DROP TRIGGER IF EXISTS trigger_auto_process_stock_movement ON process_operations;

CREATE TRIGGER trigger_auto_process_stock_movement
  AFTER UPDATE ON process_operations
  FOR EACH ROW
  EXECUTE FUNCTION auto_process_stock_movement();

COMMENT ON FUNCTION auto_process_stock_movement IS 'ê³µì • ì™„ë£Œ ì‹œ ì¬ê³  ìë™ ì´ë™ ë° ë‹¤ìŒ ê³µì • ìë™ ì‹œì‘ - ì½”ì¼â†’íŒì¬â†’ë‚©í’ˆ ìë™í™”ì˜ í•µì‹¬';
```

### Migration 4: create_material_types.sql
**ëª©ì **: ìì¬ ìœ í˜• ë¶„ë¥˜ (ì½”ì¼, íŒì¬, ì™„ì œí’ˆ ë“±)
**ìœ„í—˜ë„**: LOW (ì‹ ê·œ í…Œì´ë¸”)

```sql
-- Migration: create_material_types.sql
-- Purpose: Material type classification for manufacturing process
-- Risk: LOW - New table

CREATE TABLE IF NOT EXISTS material_types (
  type_id SERIAL PRIMARY KEY,
  type_code VARCHAR(20) UNIQUE NOT NULL,
  type_name_ko VARCHAR(100) NOT NULL,
  type_name_en VARCHAR(100),
  description TEXT,
  process_stage VARCHAR(50), -- 'RAW', 'SEMI', 'FINISHED'
  is_active BOOLEAN DEFAULT TRUE,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Insert standard material types
INSERT INTO material_types (type_code, type_name_ko, type_name_en, process_stage) VALUES
  ('RAW_MATERIAL', 'ì›ìì¬', 'Raw Material', 'RAW'),
  ('COIL', 'ì½”ì¼', 'Coil', 'RAW'),
  ('PLATE', 'íŒì¬', 'Plate', 'SEMI'),
  ('SEMI_FINISHED', 'ë°˜ì œí’ˆ', 'Semi-Finished Product', 'SEMI'),
  ('FINISHED_PRODUCT', 'ì™„ì œí’ˆ', 'Finished Product', 'FINISHED'),
  ('COMPONENT', 'ë¶€í’ˆ', 'Component', 'SEMI'),
  ('CONSUMABLE', 'ì†Œëª¨í’ˆ', 'Consumable', 'RAW');

-- Add material_type_id to items table
ALTER TABLE items
  ADD COLUMN IF NOT EXISTS material_type_id INTEGER REFERENCES material_types(type_id);

-- Update existing items (manual classification needed later)
UPDATE items SET material_type_id = (
  SELECT type_id FROM material_types WHERE type_code = 'RAW_MATERIAL'
) WHERE material_type_id IS NULL;

CREATE INDEX idx_items_material_type ON items(material_type_id);

COMMENT ON TABLE material_types IS 'ìì¬ ìœ í˜• ë¶„ë¥˜ - ì½”ì¼, íŒì¬, ì™„ì œí’ˆ ë“±';
```

### Migration 5: create_process_chain_definitions.sql
**ëª©ì **: ê³µì • ì²´ì¸ ì •ì˜ (ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ê²½ë¡œ)
**ìœ„í—˜ë„**: LOW (ì‹ ê·œ í…Œì´ë¸”)

```sql
-- Migration: create_process_chain_definitions.sql
-- Purpose: Define standard process chains (e.g., Coil â†’ Plate â†’ Delivery)
-- Risk: LOW - New table

CREATE TABLE IF NOT EXISTS process_chain_definitions (
  chain_definition_id SERIAL PRIMARY KEY,
  chain_name VARCHAR(200) NOT NULL,
  chain_description TEXT,

  -- Chain structure (JSON array of steps)
  -- Example: [
  --   {"step": 1, "operation_type": "BLANKING", "input_type": "COIL", "output_type": "PLATE"},
  --   {"step": 2, "operation_type": "PRESS", "input_type": "PLATE", "output_type": "SEMI_FINISHED"},
  --   {"step": 3, "operation_type": "SHIPPING", "input_type": "SEMI_FINISHED", "output_type": "FINISHED_PRODUCT"}
  -- ]
  chain_steps JSONB NOT NULL,

  -- Metadata
  is_active BOOLEAN DEFAULT TRUE,
  created_by INTEGER,
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW()
);

-- Insert standard chain: ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ
INSERT INTO process_chain_definitions (chain_name, chain_description, chain_steps) VALUES
(
  'ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ',
  'í‘œì¤€ ì œì¡° ê³µì •: ì½”ì¼ ë¸”ë­í‚¹ â†’ íŒì¬ í”„ë ˆìŠ¤ â†’ ì™„ì œí’ˆ ì¶œí•˜',
  '[
    {
      "step": 1,
      "operation_type": "BLANKING",
      "operation_name": "ë¸”ë­í‚¹ (ì½”ì¼ â†’ íŒì¬)",
      "input_material_type": "COIL",
      "output_material_type": "PLATE",
      "auto_next": true
    },
    {
      "step": 2,
      "operation_type": "PRESS",
      "operation_name": "í”„ë ˆìŠ¤ (íŒì¬ â†’ ì„±í˜•í’ˆ)",
      "input_material_type": "PLATE",
      "output_material_type": "SEMI_FINISHED",
      "auto_next": true
    },
    {
      "step": 3,
      "operation_type": "SHIPPING",
      "operation_name": "ì¶œí•˜ (ì„±í˜•í’ˆ â†’ ë‚©í’ˆ)",
      "input_material_type": "SEMI_FINISHED",
      "output_material_type": "FINISHED_PRODUCT",
      "auto_next": false
    }
  ]'::JSONB
);

CREATE INDEX idx_process_chain_definitions_active ON process_chain_definitions(is_active);

COMMENT ON TABLE process_chain_definitions IS 'ê³µì • ì²´ì¸ ì •ì˜ - ì½”ì¼â†’íŒì¬â†’ë‚©í’ˆ ë“± í‘œì¤€ ì œì¡° ê²½ë¡œ';
COMMENT ON COLUMN process_chain_definitions.chain_steps IS 'ê³µì • ë‹¨ê³„ ì •ì˜ (JSONB ë°°ì—´)';
```

### Migration 6: create_performance_indexes.sql
**ëª©ì **: ì„±ëŠ¥ ìµœì í™” ì¸ë±ìŠ¤
**ìœ„í—˜ë„**: LOW (ì¸ë±ìŠ¤ë§Œ ì¶”ê°€)

```sql
-- Migration: create_performance_indexes.sql
-- Purpose: Performance optimization indexes for process operations
-- Risk: LOW - Index creation only

-- Composite index for common queries
CREATE INDEX IF NOT EXISTS idx_process_operations_status_date
  ON process_operations(status, scheduled_date DESC)
  WHERE status IN ('PENDING', 'IN_PROGRESS');

CREATE INDEX IF NOT EXISTS idx_process_operations_completed_recent
  ON process_operations(completed_at DESC)
  WHERE status = 'COMPLETED' AND completed_at > NOW() - INTERVAL '90 days';

-- Index for chain queries
CREATE INDEX IF NOT EXISTS idx_process_operations_chain_active
  ON process_operations(chain_id, chain_sequence, status)
  WHERE chain_id IS NOT NULL;

-- Index for item-based queries
CREATE INDEX IF NOT EXISTS idx_process_operations_input_item
  ON process_operations(input_item_id, status);

CREATE INDEX IF NOT EXISTS idx_process_operations_output_item
  ON process_operations(output_item_id, status);

-- Partial index for recent operations (performance optimization)
CREATE INDEX IF NOT EXISTS idx_process_operations_recent_90days
  ON process_operations(created_at DESC, status)
  WHERE created_at > NOW() - INTERVAL '90 days';

-- Stock history performance indexes
CREATE INDEX IF NOT EXISTS idx_stock_history_change_type_date
  ON stock_history(change_type, created_at DESC);

CREATE INDEX IF NOT EXISTS idx_stock_history_item_recent
  ON stock_history(item_id, created_at DESC)
  WHERE created_at > NOW() - INTERVAL '90 days';

COMMENT ON INDEX idx_process_operations_status_date IS 'ì§„í–‰ ì¤‘/ëŒ€ê¸° ì¤‘ ê³µì • ë¹ ë¥¸ ì¡°íšŒ';
COMMENT ON INDEX idx_process_operations_chain_active IS 'ê³µì • ì²´ì¸ ì¡°íšŒ ìµœì í™”';
```

---

## ğŸ”Œ Backend API Implementation (5ê°œ)

### API 1: POST /api/process/start
**ëª©ì **: ìƒˆë¡œìš´ ê³µì • ì‹œì‘
**íŒŒì¼**: `src/app/api/process/start/route.ts`

```typescript
// src/app/api/process/start/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { z } from 'zod';

export const dynamic = 'force-dynamic';

const ProcessStartSchema = z.object({
  operation_type: z.enum(['BLANKING', 'PRESS', 'ASSEMBLY', 'WELDING', 'PAINTING', 'SHIPPING']),
  input_item_id: z.number().int().positive(),
  input_quantity: z.number().positive(),
  output_item_id: z.number().int().positive(),
  expected_output_quantity: z.number().positive().optional(),
  scheduled_date: z.string().datetime().optional(),
  auto_next_operation: z.boolean().default(false),
  next_operation_type: z.string().optional(),
  notes: z.string().optional(),
  created_by: z.number().int().default(1)
});

export async function POST(request: NextRequest) {
  try {
    // Korean text handling
    const text = await request.text();
    const body = JSON.parse(text);

    // Validate
    const validated = ProcessStartSchema.parse(body);

    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
    );

    // 1. Validate stock availability
    const { data: inputItem, error: itemError } = await supabase
      .from('items')
      .select('item_name, current_stock')
      .eq('item_id', validated.input_item_id)
      .single();

    if (itemError || !inputItem) {
      return NextResponse.json({
        success: false,
        error: 'íˆ¬ì… í’ˆëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
      }, { status: 404 });
    }

    if (inputItem.current_stock < validated.input_quantity) {
      return NextResponse.json({
        success: false,
        error: `ì¬ê³  ë¶€ì¡±: ${inputItem.item_name} (í•„ìš”: ${validated.input_quantity}, í˜„ì¬: ${inputItem.current_stock})`
      }, { status: 400 });
    }

    // 2. Generate LOT number
    const { data: lotNumber, error: lotError } = await supabase.rpc('generate_lot_number', {
      p_operation_type: validated.operation_type,
      p_item_id: validated.input_item_id
    });

    if (lotError) {
      return NextResponse.json({
        success: false,
        error: 'LOT ë²ˆí˜¸ ìƒì„± ì‹¤íŒ¨',
        details: lotError.message
      }, { status: 500 });
    }

    // 3. Create process operation
    const { data: operation, error: createError } = await supabase
      .from('process_operations')
      .insert({
        operation_type: validated.operation_type,
        input_item_id: validated.input_item_id,
        input_quantity: validated.input_quantity,
        output_item_id: validated.output_item_id,
        output_quantity: validated.expected_output_quantity || validated.input_quantity,
        status: 'PENDING',
        lot_number: lotNumber,
        scheduled_date: validated.scheduled_date || new Date().toISOString(),
        auto_next_operation: validated.auto_next_operation,
        next_operation_type: validated.next_operation_type,
        notes: validated.notes,
        created_by: validated.created_by
      })
      .select()
      .single();

    if (createError) {
      return NextResponse.json({
        success: false,
        error: 'ê³µì • ìƒì„± ì‹¤íŒ¨',
        details: createError.message
      }, { status: 500 });
    }

    return NextResponse.json({
      success: true,
      data: {
        operation,
        message: `ê³µì • ì‹œì‘: ${validated.operation_type} (LOT: ${lotNumber})`
      }
    });

  } catch (error) {
    if (error instanceof z.ZodError) {
      return NextResponse.json({
        success: false,
        error: 'ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨',
        details: error.errors
      }, { status: 400 });
    }

    return NextResponse.json({
      success: false,
      error: 'ì„œë²„ ì˜¤ë¥˜',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 });
  }
}
```

### API 2: POST /api/process/complete (ğŸ”¥ CRITICAL - íŠ¸ë¦¬ê±° í™œì„±í™”!)
**ëª©ì **: ê³µì • ì™„ë£Œ ë° ìë™ ì¬ê³  ì´ë™
**íŒŒì¼**: `src/app/api/process/complete/route.ts`

```typescript
// src/app/api/process/complete/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { z } from 'zod';

export const dynamic = 'force-dynamic';

const ProcessCompleteSchema = z.object({
  operation_id: z.number().int().positive(),
  actual_output_quantity: z.number().positive(),
  scrap_quantity: z.number().nonnegative().default(0),
  quality_status: z.enum(['PASS', 'FAIL', 'PENDING']).default('PASS'),
  completion_notes: z.string().optional(),
  completed_by: z.number().int().default(1)
});

export async function POST(request: NextRequest) {
  try {
    // Korean text handling
    const text = await request.text();
    const body = JSON.parse(text);

    // Validate
    const validated = ProcessCompleteSchema.parse(body);

    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
    );

    // 1. Get operation details
    const { data: operation, error: opError } = await supabase
      .from('process_operations')
      .select('*, input_item:items!input_item_id(item_name), output_item:items!output_item_id(item_name)')
      .eq('operation_id', validated.operation_id)
      .single();

    if (opError || !operation) {
      return NextResponse.json({
        success: false,
        error: 'ê³µì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
      }, { status: 404 });
    }

    if (operation.status === 'COMPLETED') {
      return NextResponse.json({
        success: false,
        error: 'ì´ë¯¸ ì™„ë£Œëœ ê³µì •ì…ë‹ˆë‹¤.'
      }, { status: 400 });
    }

    // 2. Calculate efficiency
    const efficiency = operation.output_quantity > 0
      ? (validated.actual_output_quantity / operation.output_quantity) * 100
      : 0;

    // 3. Generate child LOT number (if auto_next_operation is true)
    let childLot = null;
    if (operation.auto_next_operation && operation.next_operation_type) {
      const { data: childLotData } = await supabase.rpc('generate_lot_number', {
        p_operation_type: operation.next_operation_type,
        p_item_id: operation.output_item_id
      });
      childLot = childLotData;
    }

    // 4. âš ï¸ UPDATE OPERATION STATUS - THIS TRIGGERS auto_process_stock_movement()!
    const { data: completed, error: updateError } = await supabase
      .from('process_operations')
      .update({
        status: 'COMPLETED',
        output_quantity: validated.actual_output_quantity,
        scrap_quantity: validated.scrap_quantity,
        quality_status: validated.quality_status,
        efficiency: efficiency,
        child_lot_number: childLot,
        completed_at: new Date().toISOString(),
        notes: validated.completion_notes
          ? `${operation.notes || ''}\nì™„ë£Œ: ${validated.completion_notes}`
          : operation.notes
      })
      .eq('operation_id', validated.operation_id)
      .select()
      .single();

    if (updateError) {
      return NextResponse.json({
        success: false,
        error: 'ê³µì • ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨',
        details: updateError.message
      }, { status: 500 });
    }

    // 5. Fetch updated stock levels (íŠ¸ë¦¬ê±°ê°€ ì´ë¯¸ ì¬ê³ ë¥¼ ì—…ë°ì´íŠ¸í–ˆìŒ)
    const { data: updatedStocks } = await supabase
      .from('items')
      .select('item_id, item_name, current_stock')
      .in('item_id', [operation.input_item_id, operation.output_item_id]);

    // 6. Fetch stock history (íŠ¸ë¦¬ê±°ê°€ ê¸°ë¡í•œ ì´ë ¥)
    const { data: stockHistory } = await supabase
      .from('stock_history')
      .select('*')
      .eq('reference_type', 'process_operation')
      .eq('reference_id', validated.operation_id)
      .order('created_at', { ascending: false });

    // 7. Check if next operation was auto-created
    let nextOperation = null;
    if (operation.auto_next_operation && childLot) {
      const { data: nextOp } = await supabase
        .from('process_operations')
        .select('*')
        .eq('parent_lot_number', operation.lot_number)
        .eq('lot_number', childLot)
        .single();

      nextOperation = nextOp;
    }

    return NextResponse.json({
      success: true,
      data: {
        operation: completed,
        stock_movements: stockHistory,
        updated_stocks: updatedStocks,
        next_operation: nextOperation,
        message: 'ê³µì •ì´ ì™„ë£Œë˜ì—ˆê³  ì¬ê³ ê°€ ìë™ìœ¼ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤.',
        summary: {
          input_item: operation.input_item?.item_name,
          input_quantity: operation.input_quantity,
          output_item: operation.output_item?.item_name,
          output_quantity: validated.actual_output_quantity,
          scrap_quantity: validated.scrap_quantity,
          efficiency: `${efficiency.toFixed(2)}%`,
          lot_number: operation.lot_number,
          child_lot_number: childLot
        }
      }
    });

  } catch (error) {
    if (error instanceof z.ZodError) {
      return NextResponse.json({
        success: false,
        error: 'ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨',
        details: error.errors
      }, { status: 400 });
    }

    return NextResponse.json({
      success: false,
      error: 'ì„œë²„ ì˜¤ë¥˜',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 });
  }
}
```

### API 3: POST /api/process/chain
**ëª©ì **: ì „ì²´ ê³µì • ì²´ì¸ ì‹œì‘ (ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ)
**íŒŒì¼**: `src/app/api/process/chain/route.ts`

```typescript
// src/app/api/process/chain/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { z } from 'zod';
import { v4 as uuidv4 } from 'uuid';

export const dynamic = 'force-dynamic';

const ProcessChainSchema = z.object({
  chain_definition_id: z.number().int().positive(),
  initial_item_id: z.number().int().positive(), // ì½”ì¼ ID
  initial_quantity: z.number().positive(),
  scheduled_date: z.string().datetime().optional(),
  notes: z.string().optional(),
  created_by: z.number().int().default(1)
});

export async function POST(request: NextRequest) {
  try {
    const text = await request.text();
    const body = JSON.parse(text);
    const validated = ProcessChainSchema.parse(body);

    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
    );

    // 1. Get chain definition (ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ê²½ë¡œ)
    const { data: chainDef, error: chainError } = await supabase
      .from('process_chain_definitions')
      .select('*')
      .eq('chain_definition_id', validated.chain_definition_id)
      .eq('is_active', true)
      .single();

    if (chainError || !chainDef) {
      return NextResponse.json({
        success: false,
        error: 'ê³µì • ì²´ì¸ ì •ì˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
      }, { status: 404 });
    }

    // 2. Generate unique chain ID
    const chainId = `CHAIN-${Date.now()}-${uuidv4().substring(0, 8)}`;

    // 3. Parse chain steps
    const steps = chainDef.chain_steps as Array<{
      step: number;
      operation_type: string;
      operation_name: string;
      input_material_type: string;
      output_material_type: string;
      auto_next: boolean;
    }>;

    // 4. Create first operation only (rest will be auto-created by trigger)
    const firstStep = steps[0];
    const secondStep = steps[1] || null;

    // Generate LOT for first operation
    const { data: lotNumber } = await supabase.rpc('generate_lot_number', {
      p_operation_type: firstStep.operation_type,
      p_item_id: validated.initial_item_id
    });

    // TODO: In real implementation, need to determine output_item_id based on material type
    // For now, using placeholder logic
    const outputItemId = validated.initial_item_id; // Placeholder

    const { data: firstOperation, error: createError } = await supabase
      .from('process_operations')
      .insert({
        operation_type: firstStep.operation_type,
        input_item_id: validated.initial_item_id,
        input_quantity: validated.initial_quantity,
        output_item_id: outputItemId,
        output_quantity: validated.initial_quantity,
        status: 'PENDING',
        chain_id: chainId,
        chain_sequence: firstStep.step,
        lot_number: lotNumber,
        scheduled_date: validated.scheduled_date || new Date().toISOString(),
        auto_next_operation: firstStep.auto_next,
        next_operation_type: secondStep?.operation_type || null,
        notes: `${chainDef.chain_name} - ${firstStep.operation_name}\n${validated.notes || ''}`,
        created_by: validated.created_by
      })
      .select()
      .single();

    if (createError) {
      return NextResponse.json({
        success: false,
        error: 'ê³µì • ì²´ì¸ ì‹œì‘ ì‹¤íŒ¨',
        details: createError.message
      }, { status: 500 });
    }

    return NextResponse.json({
      success: true,
      data: {
        chain: {
          chain_id: chainId,
          chain_name: chainDef.chain_name,
          total_steps: steps.length
        },
        first_operation: firstOperation,
        message: `ê³µì • ì²´ì¸ ì‹œì‘: ${chainDef.chain_name} (${steps.length}ë‹¨ê³„)`,
        next_steps: `ì´í›„ ë‹¨ê³„ëŠ” ê° ê³µì • ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ì‹œì‘ë©ë‹ˆë‹¤.`
      }
    });

  } catch (error) {
    if (error instanceof z.ZodError) {
      return NextResponse.json({
        success: false,
        error: 'ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨',
        details: error.errors
      }, { status: 400 });
    }

    return NextResponse.json({
      success: false,
      error: 'ì„œë²„ ì˜¤ë¥˜',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 });
  }
}
```

### API 4: POST /api/process/batch
**ëª©ì **: ë‹¤ì¤‘ ê³µì • ë™ì‹œ ì‹œì‘
**íŒŒì¼**: `src/app/api/process/batch/route.ts`

```typescript
// src/app/api/process/batch/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';
import { z } from 'zod';

export const dynamic = 'force-dynamic';

const BatchProcessSchema = z.object({
  operations: z.array(z.object({
    operation_type: z.enum(['BLANKING', 'PRESS', 'ASSEMBLY', 'WELDING', 'PAINTING', 'SHIPPING']),
    input_item_id: z.number().int().positive(),
    input_quantity: z.number().positive(),
    output_item_id: z.number().int().positive(),
    expected_output_quantity: z.number().positive().optional(),
    notes: z.string().optional()
  })),
  batch_id: z.string().optional(),
  scheduled_date: z.string().datetime().optional(),
  created_by: z.number().int().default(1)
});

export async function POST(request: NextRequest) {
  try {
    const text = await request.text();
    const body = JSON.parse(text);
    const validated = BatchProcessSchema.parse(body);

    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
    );

    // Generate batch ID
    const batchId = validated.batch_id || `BATCH-${Date.now()}`;

    // Process all operations in parallel
    const results = await Promise.all(
      validated.operations.map(async (op, index) => {
        try {
          // Generate LOT
          const { data: lotNumber } = await supabase.rpc('generate_lot_number', {
            p_operation_type: op.operation_type,
            p_item_id: op.input_item_id
          });

          // Create operation
          const { data, error } = await supabase
            .from('process_operations')
            .insert({
              operation_type: op.operation_type,
              input_item_id: op.input_item_id,
              input_quantity: op.input_quantity,
              output_item_id: op.output_item_id,
              output_quantity: op.expected_output_quantity || op.input_quantity,
              status: 'PENDING',
              batch_id: batchId,
              lot_number: lotNumber,
              scheduled_date: validated.scheduled_date || new Date().toISOString(),
              notes: `ë°°ì¹˜ ${index + 1}/${validated.operations.length}: ${op.notes || ''}`,
              created_by: validated.created_by
            })
            .select()
            .single();

          if (error) throw error;

          return {
            success: true,
            operation: data,
            lot_number: lotNumber
          };

        } catch (error) {
          return {
            success: false,
            error: error instanceof Error ? error.message : 'Unknown error',
            operation_index: index
          };
        }
      })
    );

    // Aggregate results
    const successful = results.filter(r => r.success);
    const failed = results.filter(r => !r.success);

    return NextResponse.json({
      success: failed.length === 0,
      data: {
        batch_id: batchId,
        total: validated.operations.length,
        successful: successful.length,
        failed: failed.length,
        operations: successful.map(r => r.operation),
        errors: failed
      },
      message: `ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ${successful.length}/${validated.operations.length} ì„±ê³µ`
    });

  } catch (error) {
    if (error instanceof z.ZodError) {
      return NextResponse.json({
        success: false,
        error: 'ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨',
        details: error.errors
      }, { status: 400 });
    }

    return NextResponse.json({
      success: false,
      error: 'ì„œë²„ ì˜¤ë¥˜',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 });
  }
}
```

### API 5: GET /api/process/history
**ëª©ì **: ê³µì • ì´ë ¥ ì¡°íšŒ (LOT ì¶”ì , ì¬ê³  ì´ë™ ì´ë ¥)
**íŒŒì¼**: `src/app/api/process/history/route.ts`

```typescript
// src/app/api/process/history/route.ts
import { NextRequest, NextResponse } from 'next/server';
import { createClient } from '@supabase/supabase-js';

export const dynamic = 'force-dynamic';

export async function GET(request: NextRequest) {
  try {
    const { searchParams } = new URL(request.url);
    const lotNumber = searchParams.get('lot_number');
    const chainId = searchParams.get('chain_id');
    const itemId = searchParams.get('item_id');
    const startDate = searchParams.get('start_date');
    const endDate = searchParams.get('end_date');

    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
    );

    // Build query
    let query = supabase
      .from('process_operations')
      .select(`
        *,
        input_item:items!input_item_id(item_id, item_code, item_name),
        output_item:items!output_item_id(item_id, item_code, item_name)
      `);

    // Apply filters
    if (lotNumber) {
      query = query.or(`lot_number.eq.${lotNumber},parent_lot_number.eq.${lotNumber},child_lot_number.eq.${lotNumber}`);
    }

    if (chainId) {
      query = query.eq('chain_id', chainId);
    }

    if (itemId) {
      query = query.or(`input_item_id.eq.${itemId},output_item_id.eq.${itemId}`);
    }

    if (startDate) {
      query = query.gte('created_at', startDate);
    }

    if (endDate) {
      query = query.lte('created_at', endDate);
    }

    query = query.order('created_at', { ascending: false });

    const { data: operations, error: opError } = await query;

    if (opError) {
      return NextResponse.json({
        success: false,
        error: 'ê³µì • ì´ë ¥ ì¡°íšŒ ì‹¤íŒ¨',
        details: opError.message
      }, { status: 500 });
    }

    // Get stock movements for these operations
    const operationIds = operations?.map(op => op.operation_id) || [];

    const { data: stockMovements } = await supabase
      .from('stock_history')
      .select('*')
      .eq('reference_type', 'process_operation')
      .in('reference_id', operationIds)
      .order('created_at', { ascending: false });

    // Build genealogy tree if lot_number provided
    let genealogy = null;
    if (lotNumber && operations && operations.length > 0) {
      genealogy = await buildLotGenealogy(supabase, lotNumber);
    }

    return NextResponse.json({
      success: true,
      data: {
        operations: operations || [],
        stock_movements: stockMovements || [],
        genealogy,
        summary: {
          total_operations: operations?.length || 0,
          total_stock_movements: stockMovements?.length || 0
        }
      }
    });

  } catch (error) {
    return NextResponse.json({
      success: false,
      error: 'ì„œë²„ ì˜¤ë¥˜',
      details: error instanceof Error ? error.message : 'Unknown error'
    }, { status: 500 });
  }
}

// Helper function to build LOT genealogy tree
async function buildLotGenealogy(supabase: any, lotNumber: string) {
  // Find root operation
  const { data: rootOp } = await supabase
    .from('process_operations')
    .select('*')
    .eq('lot_number', lotNumber)
    .single();

  if (!rootOp) return null;

  // Build tree recursively
  const tree = {
    lot_number: rootOp.lot_number,
    operation_type: rootOp.operation_type,
    status: rootOp.status,
    parent: null as any,
    children: [] as any[]
  };

  // Get parent
  if (rootOp.parent_lot_number) {
    const { data: parentOp } = await supabase
      .from('process_operations')
      .select('lot_number, operation_type, status')
      .eq('lot_number', rootOp.parent_lot_number)
      .single();

    if (parentOp) {
      tree.parent = parentOp;
    }
  }

  // Get children
  if (rootOp.child_lot_number) {
    const { data: childOp } = await supabase
      .from('process_operations')
      .select('lot_number, operation_type, status')
      .eq('lot_number', rootOp.child_lot_number)
      .single();

    if (childOp) {
      tree.children.push(childOp);
    }
  }

  return tree;
}
```

---

## ğŸ¨ Frontend Components (3+ê°œ)

### Component 1: ProcessStartForm
**ëª©ì **: ê³µì • ì‹œì‘ í¼
**íŒŒì¼**: `src/components/process/ProcessStartForm.tsx`

```typescript
// src/components/process/ProcessStartForm.tsx
'use client';

import { useState } from 'react';
import { toast } from 'react-hot-toast';

interface ProcessStartFormProps {
  onSuccess?: (operation: any) => void;
}

export default function ProcessStartForm({ onSuccess }: ProcessStartFormProps) {
  const [formData, setFormData] = useState({
    operation_type: 'BLANKING',
    input_item_id: '',
    input_quantity: '',
    output_item_id: '',
    auto_next_operation: false,
    next_operation_type: ''
  });

  const [loading, setLoading] = useState(false);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setLoading(true);

    try {
      const response = await fetch('/api/process/start', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          ...formData,
          input_item_id: parseInt(formData.input_item_id),
          input_quantity: parseFloat(formData.input_quantity),
          output_item_id: parseInt(formData.output_item_id)
        })
      });

      const result = await response.json();

      if (result.success) {
        toast.success(result.data.message);
        onSuccess?.(result.data.operation);
        // Reset form
        setFormData({
          operation_type: 'BLANKING',
          input_item_id: '',
          input_quantity: '',
          output_item_id: '',
          auto_next_operation: false,
          next_operation_type: ''
        });
      } else {
        toast.error(result.error);
      }
    } catch (error) {
      toast.error('ê³µì • ì‹œì‘ ì‹¤íŒ¨');
    } finally {
      setLoading(false);
    }
  };

  return (
    <form onSubmit={handleSubmit} className="space-y-4 p-6 bg-white dark:bg-gray-800 rounded-lg">
      <h2 className="text-xl font-bold">ê³µì • ì‹œì‘</h2>

      <div>
        <label className="block text-sm font-medium mb-1">ê³µì • ìœ í˜•</label>
        <select
          value={formData.operation_type}
          onChange={(e) => setFormData({ ...formData, operation_type: e.target.value })}
          className="w-full px-3 py-2 border rounded dark:bg-gray-700"
        >
          <option value="BLANKING">ë¸”ë­í‚¹ (ì½”ì¼ â†’ íŒì¬)</option>
          <option value="PRESS">í”„ë ˆìŠ¤ (íŒì¬ â†’ ì„±í˜•í’ˆ)</option>
          <option value="ASSEMBLY">ì¡°ë¦½</option>
          <option value="SHIPPING">ì¶œí•˜</option>
        </select>
      </div>

      <div>
        <label className="block text-sm font-medium mb-1">íˆ¬ì… í’ˆëª© ID</label>
        <input
          type="number"
          value={formData.input_item_id}
          onChange={(e) => setFormData({ ...formData, input_item_id: e.target.value })}
          className="w-full px-3 py-2 border rounded dark:bg-gray-700"
          required
        />
      </div>

      <div>
        <label className="block text-sm font-medium mb-1">íˆ¬ì… ìˆ˜ëŸ‰</label>
        <input
          type="number"
          step="0.01"
          value={formData.input_quantity}
          onChange={(e) => setFormData({ ...formData, input_quantity: e.target.value })}
          className="w-full px-3 py-2 border rounded dark:bg-gray-700"
          required
        />
      </div>

      <div>
        <label className="block text-sm font-medium mb-1">ì‚°ì¶œ í’ˆëª© ID</label>
        <input
          type="number"
          value={formData.output_item_id}
          onChange={(e) => setFormData({ ...formData, output_item_id: e.target.value })}
          className="w-full px-3 py-2 border rounded dark:bg-gray-700"
          required
        />
      </div>

      <div className="flex items-center gap-2">
        <input
          type="checkbox"
          id="auto_next"
          checked={formData.auto_next_operation}
          onChange={(e) => setFormData({ ...formData, auto_next_operation: e.target.checked })}
        />
        <label htmlFor="auto_next" className="text-sm">
          ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë‹¤ìŒ ê³µì • ì‹œì‘
        </label>
      </div>

      {formData.auto_next_operation && (
        <div>
          <label className="block text-sm font-medium mb-1">ë‹¤ìŒ ê³µì • ìœ í˜•</label>
          <select
            value={formData.next_operation_type}
            onChange={(e) => setFormData({ ...formData, next_operation_type: e.target.value })}
            className="w-full px-3 py-2 border rounded dark:bg-gray-700"
          >
            <option value="">ì„ íƒ...</option>
            <option value="PRESS">í”„ë ˆìŠ¤</option>
            <option value="ASSEMBLY">ì¡°ë¦½</option>
            <option value="SHIPPING">ì¶œí•˜</option>
          </select>
        </div>
      )}

      <button
        type="submit"
        disabled={loading}
        className="w-full px-4 py-2 bg-blue-600 text-white rounded hover:bg-blue-700 disabled:opacity-50"
      >
        {loading ? 'ì²˜ë¦¬ ì¤‘...' : 'ê³µì • ì‹œì‘'}
      </button>
    </form>
  );
}
```

### Component 2: ProcessCompleteButton
**ëª©ì **: ê³µì • ì™„ë£Œ ë²„íŠ¼ (ì¬ê³  ìë™ ì´ë™ íŠ¸ë¦¬ê±°)
**íŒŒì¼**: `src/components/process/ProcessCompleteButton.tsx`

```typescript
// src/components/process/ProcessCompleteButton.tsx
'use client';

import { useState } from 'react';
import { toast } from 'react-hot-toast';

interface ProcessCompleteButtonProps {
  operation: any;
  onSuccess?: (result: any) => void;
}

export default function ProcessCompleteButton({ operation, onSuccess }: ProcessCompleteButtonProps) {
  const [loading, setLoading] = useState(false);
  const [showModal, setShowModal] = useState(false);
  const [actualOutput, setActualOutput] = useState(operation.output_quantity.toString());
  const [scrap, setScrap] = useState('0');
  const [quality, setQuality] = useState<'PASS' | 'FAIL' | 'PENDING'>('PASS');

  const handleComplete = async () => {
    setLoading(true);

    try {
      const response = await fetch('/api/process/complete', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          operation_id: operation.operation_id,
          actual_output_quantity: parseFloat(actualOutput),
          scrap_quantity: parseFloat(scrap),
          quality_status: quality
        })
      });

      const result = await response.json();

      if (result.success) {
        toast.success(result.data.message);

        // Show stock movements
        if (result.data.stock_movements && result.data.stock_movements.length > 0) {
          toast.success(`ì¬ê³  ì´ë™ ì™„ë£Œ: ${result.data.stock_movements.length}ê±´`);
        }

        // Show next operation if auto-created
        if (result.data.next_operation) {
          toast.success(`ë‹¤ìŒ ê³µì • ìë™ ìƒì„±: ${result.data.next_operation.operation_type}`);
        }

        setShowModal(false);
        onSuccess?.(result.data);
      } else {
        toast.error(result.error);
      }
    } catch (error) {
      toast.error('ê³µì • ì™„ë£Œ ì²˜ë¦¬ ì‹¤íŒ¨');
    } finally {
      setLoading(false);
    }
  };

  if (operation.status === 'COMPLETED') {
    return (
      <span className="text-green-600 font-medium">âœ“ ì™„ë£Œë¨</span>
    );
  }

  return (
    <>
      <button
        onClick={() => setShowModal(true)}
        className="px-4 py-2 bg-green-600 text-white rounded hover:bg-green-700"
      >
        ê³µì • ì™„ë£Œ
      </button>

      {showModal && (
        <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
          <div className="bg-white dark:bg-gray-800 p-6 rounded-lg max-w-md w-full">
            <h3 className="text-lg font-bold mb-4">ê³µì • ì™„ë£Œ</h3>

            <div className="space-y-4">
              <div>
                <label className="block text-sm font-medium mb-1">ì‹¤ì œ ì‚°ì¶œ ìˆ˜ëŸ‰</label>
                <input
                  type="number"
                  step="0.01"
                  value={actualOutput}
                  onChange={(e) => setActualOutput(e.target.value)}
                  className="w-full px-3 py-2 border rounded dark:bg-gray-700"
                />
              </div>

              <div>
                <label className="block text-sm font-medium mb-1">ë¶ˆëŸ‰ ìˆ˜ëŸ‰</label>
                <input
                  type="number"
                  step="0.01"
                  value={scrap}
                  onChange={(e) => setScrap(e.target.value)}
                  className="w-full px-3 py-2 border rounded dark:bg-gray-700"
                />
              </div>

              <div>
                <label className="block text-sm font-medium mb-1">í’ˆì§ˆ ìƒíƒœ</label>
                <select
                  value={quality}
                  onChange={(e) => setQuality(e.target.value as any)}
                  className="w-full px-3 py-2 border rounded dark:bg-gray-700"
                >
                  <option value="PASS">í•©ê²©</option>
                  <option value="FAIL">ë¶ˆí•©ê²©</option>
                  <option value="PENDING">ê²€ì‚¬ ì¤‘</option>
                </select>
              </div>

              <div className="bg-yellow-50 dark:bg-yellow-900/20 p-3 rounded border border-yellow-200 dark:border-yellow-800">
                <p className="text-sm text-yellow-800 dark:text-yellow-200">
                  âš ï¸ ì™„ë£Œ ì‹œ ì¬ê³ ê°€ ìë™ìœ¼ë¡œ ì´ë™ë©ë‹ˆë‹¤.
                </p>
                {operation.auto_next_operation && (
                  <p className="text-sm text-yellow-800 dark:text-yellow-200 mt-1">
                    âœ“ ë‹¤ìŒ ê³µì •ì´ ìë™ìœ¼ë¡œ ì‹œì‘ë©ë‹ˆë‹¤.
                  </p>
                )}
              </div>
            </div>

            <div className="flex gap-2 mt-6">
              <button
                onClick={handleComplete}
                disabled={loading}
                className="flex-1 px-4 py-2 bg-green-600 text-white rounded hover:bg-green-700 disabled:opacity-50"
              >
                {loading ? 'ì²˜ë¦¬ ì¤‘...' : 'ì™„ë£Œ'}
              </button>
              <button
                onClick={() => setShowModal(false)}
                disabled={loading}
                className="flex-1 px-4 py-2 bg-gray-500 text-white rounded hover:bg-gray-600 disabled:opacity-50"
              >
                ì·¨ì†Œ
              </button>
            </div>
          </div>
        </div>
      )}
    </>
  );
}
```

---

## ğŸ§ª E2E Testing Strategy

### Critical Test: ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ì „ì²´ íë¦„
**íŒŒì¼**: `tests/e2e/process/full-chain.spec.ts`

```typescript
// tests/e2e/process/full-chain.spec.ts
import { test, expect } from '@playwright/test';

test.describe('ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ì „ì²´ ê³µì • íë¦„', () => {
  test('ìë™ ì¬ê³  ì´ë™ ë° ê³µì • ì²´ì¸ ê²€ì¦', async ({ page }) => {
    // 1. ì´ˆê¸° ì¬ê³  í™•ì¸
    await page.goto('http://localhost:5000/stock');

    const initialCoilStock = await page.locator('[data-testid="item-stock-COIL001"]').textContent();
    const initialPlateStock = await page.locator('[data-testid="item-stock-PLATE001"]').textContent();

    console.log('ì´ˆê¸° ì¬ê³ :', { coil: initialCoilStock, plate: initialPlateStock });

    // 2. ë¸”ë­í‚¹ ê³µì • ì‹œì‘ (ì½”ì¼ â†’ íŒì¬)
    await page.goto('http://localhost:5000/process');
    await page.click('[data-testid="start-process-btn"]');

    await page.selectOption('[data-testid="operation-type"]', 'BLANKING');
    await page.fill('[data-testid="input-item-id"]', 'COIL001');
    await page.fill('[data-testid="input-quantity"]', '100');
    await page.fill('[data-testid="output-item-id"]', 'PLATE001');
    await page.check('[data-testid="auto-next-operation"]');
    await page.selectOption('[data-testid="next-operation-type"]', 'PRESS');

    await page.click('[data-testid="submit-process"]');

    // LOT ë²ˆí˜¸ í™•ì¸
    const lotNumber = await page.locator('[data-testid="lot-number"]').textContent();
    expect(lotNumber).toMatch(/BLK-\d{8}-\d{3}/);

    console.log('ë¸”ë­í‚¹ LOT:', lotNumber);

    // 3. ë¸”ë­í‚¹ ì™„ë£Œ
    await page.click(`[data-testid="complete-operation-${lotNumber}"]`);
    await page.fill('[data-testid="actual-output"]', '98'); // 2% ë¶ˆëŸ‰
    await page.fill('[data-testid="scrap-quantity"]', '2');
    await page.selectOption('[data-testid="quality-status"]', 'PASS');
    await page.click('[data-testid="confirm-complete"]');

    // ì™„ë£Œ ë©”ì‹œì§€ í™•ì¸
    await expect(page.locator('.toast-success')).toContainText('ì¬ê³ ê°€ ìë™ìœ¼ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤');

    // 4. ì¬ê³  ì´ë™ ê²€ì¦
    await page.goto('http://localhost:5000/stock');

    const afterBlankingCoilStock = await page.locator('[data-testid="item-stock-COIL001"]').textContent();
    const afterBlankingPlateStock = await page.locator('[data-testid="item-stock-PLATE001"]').textContent();

    expect(parseFloat(afterBlankingCoilStock!)).toBe(parseFloat(initialCoilStock!) - 100);
    expect(parseFloat(afterBlankingPlateStock!)).toBe(parseFloat(initialPlateStock!) + 98);

    console.log('ë¸”ë­í‚¹ í›„ ì¬ê³ :', { coil: afterBlankingCoilStock, plate: afterBlankingPlateStock });

    // 5. ë‹¤ìŒ ê³µì • ìë™ ìƒì„± í™•ì¸ (í”„ë ˆìŠ¤)
    await page.goto('http://localhost:5000/process');

    const pressOperation = await page.locator('[data-testid^="operation-PRS-"]').first();
    await expect(pressOperation).toBeVisible();

    const pressLotNumber = await pressOperation.getAttribute('data-testid');
    expect(pressLotNumber).toMatch(/PRS-\d{8}-\d{3}/);

    console.log('ìë™ ìƒì„±ëœ í”„ë ˆìŠ¤ LOT:', pressLotNumber);

    // 6. LOT ì¶”ì  ê²€ì¦
    await page.goto(`http://localhost:5000/process/history?lot_number=${lotNumber}`);

    const genealogy = await page.locator('[data-testid="lot-genealogy"]');
    await expect(genealogy).toContainText(lotNumber!); // Parent LOT
    await expect(genealogy).toContainText(pressLotNumber!); // Child LOT

    // 7. ì¬ê³  ì´ë ¥ ê²€ì¦
    const stockHistory = await page.locator('[data-testid="stock-history"]');
    await expect(stockHistory).toContainText('BLANKING_INPUT'); // ì½”ì¼ ì°¨ê°
    await expect(stockHistory).toContainText('BLANKING_OUTPUT'); // íŒì¬ ì¶”ê°€

    console.log('âœ… ì „ì²´ ê³µì • íë¦„ ê²€ì¦ ì™„ë£Œ');
  });
});
```

---

## ğŸš€ Deployment Plan

### Migration Deployment Sequence

```bash
# 1. Backup current database
psql $SUPABASE_DB_URL -c "SELECT COUNT(*) FROM process_operations;"

# 2. Apply migrations in order (CRITICAL!)
psql $SUPABASE_DB_URL -f supabase/migrations/20250206_create_stock_history.sql
psql $SUPABASE_DB_URL -f supabase/migrations/20250206_extend_process_operations.sql
psql $SUPABASE_DB_URL -f supabase/migrations/20250206_create_auto_stock_movement_trigger.sql  # ğŸ”¥ CORE!
psql $SUPABASE_DB_URL -f supabase/migrations/20250206_create_material_types.sql
psql $SUPABASE_DB_URL -f supabase/migrations/20250206_create_process_chain_definitions.sql
psql $SUPABASE_DB_URL -f supabase/migrations/20250206_create_performance_indexes.sql

# 3. Verify migrations
psql $SUPABASE_DB_URL -c "SELECT * FROM pg_trigger WHERE tgname = 'trigger_auto_process_stock_movement';"

# 4. Smoke test (create test operation and complete it)
curl -X POST http://localhost:5000/api/process/start \
  -H "Content-Type: application/json" \
  -d '{"operation_type":"BLANKING","input_item_id":1,"input_quantity":10,"output_item_id":2}'

# Get operation ID from response, then complete it
curl -X POST http://localhost:5000/api/process/complete \
  -H "Content-Type: application/json" \
  -d '{"operation_id":XXX,"actual_output_quantity":9.5,"scrap_quantity":0.5}'

# 5. Verify stock movement in database
psql $SUPABASE_DB_URL -c "SELECT * FROM stock_history ORDER BY created_at DESC LIMIT 10;"

# 6. Monitor logs
tail -f logs/process_automation.log
```

### Rollback Scripts

```sql
-- rollback_auto_stock_movement.sql
DROP TRIGGER IF EXISTS trigger_auto_process_stock_movement ON process_operations;
DROP FUNCTION IF EXISTS auto_process_stock_movement();

-- rollback_all_migrations.sql
DROP TABLE IF EXISTS stock_history CASCADE;
DROP TABLE IF EXISTS process_chain_definitions CASCADE;
DROP TABLE IF EXISTS material_types CASCADE;
DROP FUNCTION IF EXISTS generate_lot_number(VARCHAR, INTEGER);

ALTER TABLE process_operations
  DROP COLUMN IF EXISTS parent_operation_id,
  DROP COLUMN IF EXISTS chain_id,
  DROP COLUMN IF EXISTS chain_sequence,
  DROP COLUMN IF EXISTS lot_number,
  DROP COLUMN IF EXISTS parent_lot_number,
  DROP COLUMN IF EXISTS child_lot_number,
  DROP COLUMN IF EXISTS batch_id,
  DROP COLUMN IF EXISTS auto_next_operation,
  DROP COLUMN IF EXISTS next_operation_type,
  DROP COLUMN IF EXISTS scrap_quantity,
  DROP COLUMN IF EXISTS quality_status;
```

---

## ğŸ“‹ Agent Execution Commands

### Wave 1: Foundation Design (Day 1-2)

```bash
# Track A: Database Schema Design
claude-code --agent database-architect \
  --task "Design 6 database migrations for process automation" \
  --context ".plan8/IMPLEMENTATION_PLAN.md" \
  --output ".plan8/migrations/"

# Track B: API Architecture Planning
claude-code --agent backend-architect \
  --task "Design 5 API endpoints for process management" \
  --context ".plan8/IMPLEMENTATION_PLAN.md" \
  --output ".plan8/api-specs/"

# Track C: UI Component Design
claude-code --agent frontend-developer \
  --task "Design process management UI components" \
  --context ".plan8/IMPLEMENTATION_PLAN.md" \
  --output ".plan8/component-specs/"
```

### Wave 2: Core Implementation (Day 3-5)

```bash
# Track A: Database Migrations
claude-code --agent database-architect \
  --task "Implement and test 6 database migrations" \
  --files "supabase/migrations/20250206_*.sql" \
  --validate

# Track B: Backend APIs
claude-code --agent backend-architect \
  --task "Implement 5 process management APIs" \
  --files "src/app/api/process/**/*.ts" \
  --test

# Track C: Frontend Components
claude-code --agent frontend-developer \
  --task "Implement process management UI" \
  --files "src/components/process/**/*.tsx" \
  --test

# Track D: RLS Policies
claude-code --agent supabase-schema-architect \
  --task "Implement RLS policies for new tables" \
  --files "supabase/migrations/20250206_rls_policies.sql"
```

### Wave 3: Advanced Features (Day 6-7)

```bash
# Track A: Batch Processing
claude-code --agent backend-architect,frontend-developer \
  --task "Implement batch process mode" \
  --files "src/app/api/process/batch/**,src/components/process/BatchProcessGrid.tsx"

# Track B: Chain Automation
claude-code --agent backend-architect \
  --task "Implement process chain automation" \
  --files "src/app/api/process/chain/**"

# Track C: Real-time Dashboard
claude-code --agent frontend-developer \
  --task "Implement real-time process dashboard" \
  --files "src/components/process/ProcessDashboard.tsx"
```

### Wave 4: Testing & Optimization (Day 8-9)

```bash
# Track A: E2E Testing
claude-code --agent qa \
  --task "Run comprehensive E2E tests for process automation" \
  --test "tests/e2e/process/**/*.spec.ts" \
  --critical "ì½”ì¼ â†’ íŒì¬ â†’ ë‚©í’ˆ ì „ì²´ íë¦„"

# Track B: Performance Optimization
claude-code --agent performance \
  --task "Optimize process queries and triggers" \
  --analyze "Database performance metrics" \
  --optimize
```

### Wave 5: Production Deployment (Day 10)

```bash
# Track A: Deployment
claude-code --agent devops \
  --task "Deploy process automation to production" \
  --deploy \
  --monitor \
  --rollback-ready
```

---

## âœ… Success Criteria

### ì¡°ì„±ì§„ ì°¨ì¥ë‹˜ ìš”êµ¬ì‚¬í•­ 100% ì¶©ì¡± ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] **ì½”ì¼ â†’ íŒì¬ ìë™ ì¬ê³  ì´ë™**: auto_process_stock_movement() íŠ¸ë¦¬ê±° ì‘ë™
- [ ] **íŒì¬ â†’ ì™„ì œí’ˆ ìë™ ì¬ê³  ì´ë™**: ì—°ì† ê³µì • ì²´ì¸ ì‘ë™
- [ ] **ì™„ì œí’ˆ â†’ ë‚©í’ˆ ìë™ ì¬ê³  ì´ë™**: ì¶œí•˜ ê³µì • ì¬ê³  ì´ë™
- [ ] **BOMê³¼ ê³µì • íë¦„ ì¼ì¹˜**: process_chain_definitionsë¡œ í‘œì¤€ ê²½ë¡œ ì •ì˜
- [ ] **LOT ì¶”ì **: ë¶€ëª¨ â†’ ìì‹ LOT genealogy ì™„ë²½ ì‘ë™
- [ ] **ì¬ê³  ê°ì‚¬ ì¶”ì **: stock_historyì— ëª¨ë“  ì´ë™ ê¸°ë¡
- [ ] **ìë™ ë‹¤ìŒ ê³µì • ì‹œì‘**: auto_next_operation í”Œë˜ê·¸ë¡œ ì²´ì¸ ìë™í™”
- [ ] **ë°°ì¹˜ ì²˜ë¦¬**: ë‹¤ì¤‘ ê³µì • ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥
- [ ] **E2E í…ŒìŠ¤íŠ¸**: ì „ì²´ íë¦„ ê²€ì¦ ì™„ë£Œ
- [ ] **Production ë°°í¬**: ëª¨ë“  ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ê³µ, ëª¨ë‹ˆí„°ë§ í™œì„±í™”

---

## ğŸ“Š Timeline Summary

| Wave | Days | Tasks | Critical Path |
|------|------|-------|---------------|
| Wave 1 | 1-2 | ì„¤ê³„ (DB + API + UI) | ë§ˆì´ê·¸ë ˆì´ì…˜ ì„¤ê³„ ì™„ë£Œ |
| Wave 2 | 3-5 | í•µì‹¬ êµ¬í˜„ | auto_stock_movement íŠ¸ë¦¬ê±° |
| Wave 3 | 6-7 | ê³ ê¸‰ ê¸°ëŠ¥ | ë°°ì¹˜ + ì²´ì¸ ìë™í™” |
| Wave 4 | 8-9 | í…ŒìŠ¤íŠ¸ + ìµœì í™” | E2E ì „ì²´ íë¦„ ê²€ì¦ |
| Wave 5 | 10 | ë°°í¬ + ëª¨ë‹ˆí„°ë§ | Production ë°°í¬ |

**Total**: 9-10 days with parallel execution

---

## ğŸ¯ Next Immediate Steps

1. **Read this plan** - User approval
2. **Execute Codex analysis** - Current codebase gaps
3. **Launch Wave 1 Track A** - Database schema design (database-architect)
4. **Launch Wave 1 Track B** - API architecture planning (backend-architect)
5. **Launch Wave 1 Track C** - UI component design (frontend-developer)

---

**Plan Created**: 2025-02-05
**Status**: Ready for Execution
**Priority**: CRITICAL - ì™„ë²½í•œ êµ¬í˜„ í•„ìˆ˜
**Approval**: Awaiting User Confirmation

